{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from PIL import Image\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Activation, BatchNormalization, \\\n",
    "    GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "# from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "data = '/kaggle/input/plantvillage-dataset/color'\n",
    "class_folds = os.listdir(data)\n",
    "\n",
    "\n",
    "def create_dataframe(data_path):\n",
    "    # List to store filepaths and labels\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    # List all subfolders in the current data path\n",
    "    folds = os.listdir(data_path)\n",
    "\n",
    "    # Iterate through each subfolder\n",
    "    for fold in folds:\n",
    "        f_path = os.path.join(data_path, fold)\n",
    "        imgs = os.listdir(f_path)\n",
    "\n",
    "        # Iterate through images in the subfolder\n",
    "        for img in imgs:\n",
    "            img_path = os.path.join(f_path, img)\n",
    "\n",
    "            # Append image path and corresponding label\n",
    "            filepaths.append(img_path)\n",
    "            labels.append(fold)\n",
    "\n",
    "    # Create Pandas Series for filepaths and labels\n",
    "    fseries = pd.Series(filepaths, name='Filepaths')\n",
    "    lseries = pd.Series(labels, name='Labels')\n",
    "\n",
    "    # Concatenate into a DataFrame and return\n",
    "    return pd.concat([fseries, lseries], axis=1)\n",
    "\n",
    "\n",
    "# Create DataFrames for train, test, and val\n",
    "df = create_dataframe(data)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.shape\n",
    "\n",
    "print(\"The classes:\\n\", np.unique(df['Labels']))\n",
    "\n",
    "# Count the number of images in each class\n",
    "class_counts = df['Labels'].value_counts()\n",
    "class_counts\n",
    "\n",
    "# Visualize class distribution using a horizontal bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.barplot(x=class_counts.values, y=class_counts.index, orient='h')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Number of Images')\n",
    "plt.ylabel('Plant Types')\n",
    "plt.tight_layout()  # Adjust the layout to prevent overlapping labels\n",
    "\n",
    "# Add data labels to each bar\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    ax.text(v + 5, i, str(v), color='black', va='center')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and test sets 80% training, 20% test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df.shape, test_df.shape\n",
    "\n",
    "# Split the training data into training and validation sets (80% training, 20% validation)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df.shape, val_df.shape\n",
    "\n",
    "# Display sample images from each class\n",
    "num_classes = len(df['Labels'].unique())\n",
    "num_images_per_row = 4\n",
    "num_rows = (num_classes + num_images_per_row - 1) // num_images_per_row\n",
    "\n",
    "plt.figure(figsize=(15, 5 * num_rows))  # Adjust figure size based on the number of rows\n",
    "\n",
    "for i, plant_class in enumerate(df['Labels'].unique()):\n",
    "    plt.subplot(num_rows, num_images_per_row, i + 1)\n",
    "\n",
    "    # Inside the loop for displaying sample images\n",
    "    image_path = os.path.join(data, df[df['Labels'] == plant_class]['Filepaths'].iloc[0])\n",
    "\n",
    "    # Check if the image exists and can be loaded\n",
    "    if os.path.exists(image_path):\n",
    "        sample_image = cv2.imread(image_path)\n",
    "        if sample_image is not None:\n",
    "            plt.imshow(cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(plant_class)\n",
    "            plt.axis('off')\n",
    "        else:\n",
    "            print(f\"Error: Unable to load image from path: {fseries}\")\n",
    "    else:\n",
    "        print(f\"Error: Image path does not exist: {fseries}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Generate images from dataframe \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,  # Rescale pixel values to [0, 1]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1. / 255)  # Only rescaling for validation and test\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Create flow_from_dataframe generators for train, validation, and test\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepaths',\n",
    "    y_col='Labels',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for multi-class classification\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Filepaths',\n",
    "    y_col='Labels',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for multi-class classification\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepaths',\n",
    "    y_col='Labels',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'categorical' for multi-class classification\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "#Generic Model Creation### AVG pool\n",
    "base_model = tf.keras.applications.xception.Xception(weights='imagenet', include_top=False,\n",
    "                                                     input_shape=(224, 224, 3), pooling='avg')\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(.5),\n",
    "    Dense(38, activation='softmax')\n",
    "])\n",
    "#Training Model \n",
    "model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=5, verbose=1,\n",
    "    validation_steps=None, shuffle=False\n",
    ")\n",
    "\n",
    "#test (AVG POOL & epochs=1 0) %99.1\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(test_generator)\n",
    "test_predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Get the true labels for the test set\n",
    "\n",
    "# Create a DataFrame for analysis\n",
    "error_df = pd.DataFrame({'True Label': test_true_labels, 'Predicted Label': test_predicted_labels})\n",
    "\n",
    "# Misclassified images\n",
    "misclassified_images = error_df[error_df['True Label'] != error_df['Predicted Label']]\n",
    "\n",
    "# Visualization of misclassified images\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, row in enumerate(misclassified_images.head(9).itertuples()):\n",
    "    img_path = test_df.iloc[row.Index]['Filepaths']\n",
    "    img = keras_image.load_img(img_path, target_size=(224, 224))\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(img)\n",
    "    true_label = class_folds[row._1]  # Use 'True Label' as defined in error_df\n",
    "    pred_label = class_folds[row._2]  # Use 'Predicted Label' as defined in error_df\n",
    "    plt.title(f'True: {true_label}\\nPred: {pred_label}')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "class_labels_dict = {class_label: idx for idx, class_label in enumerate(np.unique(df['Labels']))}\n",
    "df['Labels'] = df['Labels'].map(class_labels_dict)\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "plt.figure(figsize=(14, 12))\n",
    "conf_matrix = confusion_matrix(test_true_labels, test_predicted_labels)\n",
    "class_names = list(class_labels_dict.keys())\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show\n",
    "\n",
    "print(classification_report(test_true_labels, test_predicted_labels, target_names=class_names))\n",
    "\n",
    "# Unfreeze more layers in the Xception model\n",
    "n = 40\n",
    "for layer in model.layers[:-n]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Adjust the learning rate for fine-tuning\n",
    "learning_rate_finetune = 0.00001\n",
    "\n",
    "# Compile the model with the updated learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate_finetune), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fine-tuning\n",
    "epochs_finetune = 5\n",
    "history_finetune = model.fit(train_generator, epochs=epochs_finetune, validation_data=valid_generator)\n",
    "\n",
    "#test (AVG POOL & epochs=10) %99.7 \n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "plt.figure(figsize=(14, 12))\n",
    "conf_matrix = confusion_matrix(test_true_labels, test_predicted_labels)\n",
    "class_names = list(class_labels_dict.keys())\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show\n",
    "\n",
    "print(classification_report(test_true_labels, test_predicted_labels, target_names=class_names))\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
